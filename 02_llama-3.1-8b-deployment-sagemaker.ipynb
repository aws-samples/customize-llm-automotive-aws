{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model deployment of Fine-Tuned Llama 3.1 8B in Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In this demo notebook, we demonstrate how to deploy the fine-tuned model from the notebook [01_llama-3.1-8b-qlora-sft.ipynb](./01_llama-3.1-8b-qlora-sft.ipynb) in an Amazon SageMaker real-time endpoint.\n",
    "\n",
    "---\n",
    "\n",
    "JupyterLab Instance Type: ml.t3.medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required libriaries, including the Hugging Face libraries, and restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.45.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (4.45.1)\n",
      "Requirement already satisfied: peft==0.12.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: accelerate==0.34.2 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.34.2)\n",
      "Requirement already satisfied: bitsandbytes==0.44.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.44.0)\n",
      "Requirement already satisfied: datasets==2.20.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.20.0)\n",
      "Requirement already satisfied: evaluate==0.4.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: nltk==3.9.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (3.9.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (0.4.5)\n",
      "Requirement already satisfied: sagemaker==2.232.2 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (2.232.2)\n",
      "Requirement already satisfied: sentencepiece==0.2.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: scikit-learn==1.5.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (1.5.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.20.3)\n",
      "Requirement already satisfied: py7zr in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (0.22.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers==4.45.1->-r requirements.txt (line 1)) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers==4.45.1->-r requirements.txt (line 1)) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.45.1->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.45.1->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.45.1->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.45.1->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.45.1->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.45.1->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft==0.12.0->-r requirements.txt (line 2)) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft==0.12.0->-r requirements.txt (line 2)) (2.4.1.post100)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.20.0->-r requirements.txt (line 5)) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets==2.20.0->-r requirements.txt (line 5)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.20.0->-r requirements.txt (line 5)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==2.20.0->-r requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets==2.20.0->-r requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets==2.20.0->-r requirements.txt (line 5)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets==2.20.0->-r requirements.txt (line 5)) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets==2.20.0->-r requirements.txt (line 5)) (3.9.5)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1->-r requirements.txt (line 6)) (0.18.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk==3.9.1->-r requirements.txt (line 7)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk==3.9.1->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.34.142 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (1.36.11)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (2.2.1)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (7.1.0)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (4.23.0)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (4.3.6)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (4.25.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (1.0.20)\n",
      "Requirement already satisfied: sagemaker-mlflow in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (0.1.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (2.0.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.232.2->-r requirements.txt (line 9)) (1.26.19)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.5.1->-r requirements.txt (line 11)) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.5.1->-r requirements.txt (line 11)) (3.5.0)\n",
      "Requirement already satisfied: texttable in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 13)) (1.7.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 13)) (3.21.0)\n",
      "Requirement already satisfied: pyzstd>=0.15.9 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 13)) (0.16.2)\n",
      "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 13)) (1.1.1)\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 13)) (1.0.3)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 13)) (0.2.3)\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 13)) (1.0.1)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 13)) (1.1.0)\n",
      "Requirement already satisfied: botocore<1.37.0,>=1.36.11 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.34.142->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.36.11)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.34.142->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.34.142->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.11.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.20.0->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.20.0->-r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.20.0->-r requirements.txt (line 5)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.20.0->-r requirements.txt (line 5)) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.1->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.21.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.45.1->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.45.1->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.45.1->-r requirements.txt (line 1)) (2024.8.30)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.2->-r requirements.txt (line 9)) (2.10.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.2->-r requirements.txt (line 9)) (13.9.4)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.2->-r requirements.txt (line 9)) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.232.2->-r requirements.txt (line 9)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.22.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.12.0->-r requirements.txt (line 2)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.12.0->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.12.0->-r requirements.txt (line 2)) (3.1.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from google-pasta->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.20.0->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.20.0->-r requirements.txt (line 5)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.20.0->-r requirements.txt (line 5)) (2024.2)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.7.6.9)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.3.5)\n",
      "Requirement already satisfied: mlflow>=2.8 in /opt/conda/lib/python3.11/site-packages (from sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (2.17.2)\n",
      "Requirement already satisfied: Flask<4 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.1.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.14.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (5.5.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.39.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.1.43)\n",
      "Requirement already satisfied: graphene<4 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.6)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.9.3)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.28.2)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (2.0.36)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.5.3)\n",
      "Requirement already satisfied: gunicorn<24 in /opt/conda/lib/python3.11/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (22.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft==0.12.0->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.2->-r requirements.txt (line 9)) (2.27.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.2->-r requirements.txt (line 9)) (2.18.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets==2.20.0->-r requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft==0.12.0->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.3.8)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/conda/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (2.36.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /opt/conda/lib/python3.11/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /opt/conda/lib/python3.11/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /opt/conda/lib/python3.11/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (4.0.11)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.11/site-packages (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.11/site-packages (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.2.15)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.49b2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (3.1.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (1.17.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow>=2.8->sagemaker-mlflow->sagemaker==2.232.2->-r requirements.txt (line 9)) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U boto3\n",
    "%pip install -q -U botocore\n",
    "%pip install -q -U Levenshtein\n",
    "%pip install -q -U scikit-learn==1.5.1\n",
    "%pip install -q -U seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup Configuration file path\n",
    "\n",
    "We are setting the directory in which the config.yaml file resides so that remote decorator can make use of the settings through [SageMaker Defaults](https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk).\n",
    "\n",
    "This notebook is using the Hugging Face container for the `us-east-1` region. Make sure you are using the right image for your AWS region, otherwise edit [config.yaml](./config.yaml). Container Images are available [here](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set path to config file\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy the Fine-Tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Fetched defaults config from location: /home/sagemaker-user/personalgithubrepo/customize-llm-automotive-aws\n"
     ]
    }
   ],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "job_prefix = f\"train-{model_id.split('/')[-1].replace('.', '-')}-auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_job_name(job_name_prefix):\n",
    "    import boto3\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "    search_response = sagemaker_client.search(\n",
    "        Resource='TrainingJob',\n",
    "        SearchExpression={\n",
    "            'Filters': [\n",
    "                {\n",
    "                    'Name': 'TrainingJobName',\n",
    "                    'Operator': 'Contains',\n",
    "                    'Value': job_name_prefix\n",
    "                },\n",
    "                {\n",
    "                    'Name': 'TrainingJobStatus',\n",
    "                    'Operator': 'Equals',\n",
    "                    'Value': \"Completed\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        SortBy='CreationTime',\n",
    "        SortOrder='Descending',\n",
    "        MaxResults=1)\n",
    "\n",
    "    return search_response['Results'][0]['TrainingJob']['TrainingJobName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train-Meta-Llama-3-1-8B-Instruct-auto-2025-02-03-11-42-49-388'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = get_last_job_name(job_prefix)\n",
    "\n",
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Inference configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.g5.4xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.Model.EnableNetworkIsolation\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "model = HuggingFaceModel(\n",
    "    image_uri='763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.4.0-tgi2.3.1-gpu-py311-cu124-ubuntu22.04-v2.0', #image_uri with py311\n",
    "    model_data=f\"s3://{bucket_name}/{job_name}/{job_name}/output/model.tar.gz\",\n",
    "    role=get_execution_role(),\n",
    "    env={\n",
    "        'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "        'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "        'HF_MODEL_QUANTIZE': 'bitsandbytes',\n",
    "        'MAX_INPUT_LENGTH': '4096',\n",
    "        'MAX_TOTAL_TOKENS': '8192'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=health_check_timeout,\n",
    "    model_data_download_timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation - Fine-tuned model vs. Base model\n",
    "\n",
    "We are going to evaluate the fine-tuned model and the base model on two metrics:\n",
    "* BLEU Score\n",
    "* Accuracy score with Levenshtein distance\n",
    "\n",
    "BLEU (bilingual evaluation understudy) is an algorithm for evaluating the quality of text which has been machine-translated from one natural language to another.\n",
    "\n",
    "\n",
    "Normalized Levenshtein distance is an algorithm for evaluating accuracy degree of how close the calculated or measured values are to the actual value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFacePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"<ENDPOINT_NAME>\" #Required if you want to create a predictor without running the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'predictor' not in locals() and 'predictor' not in globals():\n",
    "    print(\"Create predictor\")\n",
    "    predictor = HuggingFacePredictor(\n",
    "        endpoint_name=endpoint_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Amazon Bedrock client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_model_id = \"meta.llama3-8b-instruct-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./sample_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation elements:  10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train, valid = train_test_split(train, test_size=10, random_state=42)\n",
    "\n",
    "print(\"Number of validation elements: \", len(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PACCAR Incorporated (PACCAR) is recalling certain model year 2011-2016 Kenworth T270, T370, T440, T470, C500, C540, C550, T660, T800, W900, and 963 trucks manufactured November 1, 2010, to April 6, 2015.  In the affected trucks, water may leak into the wiper motor.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us first do a small test...\n",
    "row = valid.iloc[0]\n",
    "row['DESC_DEFECT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_defect_request_body(row, top_p=0.9, temperature=0.2, max_new_tokens=512):\n",
    "    prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>These are the information related to the defect:\\nManufacturer: {row['MFGNAME']}\\nComponent: {row['COMPNAME']}\\nDescription of the defect: {row['DESC_DEFECT']}\\n\\n\\nWhat are the consequences of defect?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "    return {\n",
    "        'inputs': prompt,\n",
    "        'parameters': {\n",
    "            \"top_p\": top_p,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_new_tokens\": max_new_tokens,\n",
    "            \"return_full_text\": False,\n",
    "            \"stop\": [\n",
    "                '<|eot_id|>',\n",
    "                '<|end_of_text|>'\n",
    "            ]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'malfunctioning exterior marker lights can increase the risk of a crash.'}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(build_defect_request_body(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example  2733\n",
      "Generated response with fine-tuned model: 2.240939 seconds\n",
      "water leaking into the wiper motor may cause the wiper motor to fail, reducing the driver's visibility and increasing the risk of a crash.\n",
      "Generated response with base model: 1.475031 seconds\n",
      "\n",
      "\n",
      "Based on the information provided, the consequences of the defect are:\n",
      "\n",
      "* Water may leak into the wiper motor.\n",
      "\n",
      "This could potentially lead to:\n",
      "\n",
      "* Malfunctioning or failure of the wiper motor\n",
      "* Reduced visibility while driving, which could increase the risk of accidents\n",
      "* Potential damage to other electrical components in the vehicle\n",
      "* Increased risk of corrosion or rust in the wiper motor and surrounding areas\n",
      "\n",
      "It is recommended that the affected vehicles be inspected and repaired by a qualified technician to prevent these potential consequences.\n",
      "******************\n",
      "Example  3382\n",
      "Generated response with fine-tuned model: 2.103293 seconds\n",
      "In the event of a fire, the seat may not provide the necessary protection to the occupant, increasing the risk of injury.\n",
      "Generated response with base model: 1.796597 seconds\n",
      "\n",
      "\n",
      "According to the information provided, the consequences of the defect are that the affected school bus seat assemblies may not meet the flammability requirements of Federal Motor Vehicle Safety Standard (FMVSS) No. 302, \"Flammability of Interior Materials.\" This means that there is a risk of the seats not being able to withstand a fire or other high-temperature situation, which could potentially lead to:\n",
      "\n",
      "* Increased risk of injury or harm to occupants in the event of a fire or other emergency\n",
      "* Non-compliance with safety regulations, which could result in fines, penalties, or even the removal of the affected vehicles from service\n",
      "* Potential damage to the vehicle or its components, which could lead to costly repairs or even total loss of the vehicle\n",
      "* Negative impact on the reputation of the manufacturer and the school bus industry as a whole.\n",
      "******************\n",
      "Example  1198\n",
      "Generated response with fine-tuned model: 2.446176 seconds\n",
      "corrosion of the front cross member may cause the front control arm to break, resulting in a loss of vehicle control, increasing the risk of a crash.\n",
      "Generated response with base model: 0.967147 seconds\n",
      "\n",
      "\n",
      "Based on the information provided, the consequences of the defect are:\n",
      "\n",
      "* Corrosion of the front cross member after exposure to road salt.\n",
      "\n",
      "This defect may lead to structural damage or failure of the suspension system, which could potentially cause:\n",
      "\n",
      "* Loss of vehicle stability and control\n",
      "* Reduced braking performance\n",
      "* Increased risk of accidents or injuries\n",
      "\n",
      "It is essential to address this defect to ensure the safety and reliability of the vehicle.\n",
      "******************\n",
      "Example  2942\n",
      "Generated response with fine-tuned model: 3.789254 seconds\n",
      "various system malfunctions such as inoperative windshield wipers, defroster, rearview camera, or exterior lighting can reduce visibility and make it difficult to stop the vehicle, either increasing the risk of a crash or a pedestrian being hit.\n",
      "Generated response with base model: 1.961707 seconds\n",
      "\n",
      "\n",
      "According to the information provided, the consequences of the software error in the Body Control Module (BCM) are:\n",
      "\n",
      "1. Intermittent or continuous disruptions in communication between the BCM and other components.\n",
      "2. Malfunctions of various systems, including:\n",
      "\t* Windshield wipers and defroster\n",
      "\t* Rearview camera\n",
      "\t* Exterior lights\n",
      "\t* Audible warning of a stopped vehicle\n",
      "\t* Power window operation\n",
      "\n",
      "These malfunctions may lead to a failure to comply with the requirements of Federal Motor Vehicle Safety Standards (FMVSS) numbers 103, 111, 104, 108, 114, 118, and 305, which are related to:\n",
      "\n",
      "1. Windshield defrosting and defogging systems\n",
      "2. Rear visibility\n",
      "3. Various safety and performance standards\n",
      "\n",
      "As a result, the vehicles may not operate safely or effectively, which could increase the risk of accidents or injuries.\n",
      "******************\n",
      "Example  5151\n",
      "Generated response with fine-tuned model: 3.278529 seconds\n",
      "EXCESS PRESSURE IN THE FUEL PUMP CAN CAUSE THE FUEL PUMP TO FAIL, LEADING TO A VEHICLE STALL INCREASING THE RISK OF A CRASH.\n",
      "Generated response with base model: 1.063624 seconds\n",
      "\n",
      "\n",
      "According to the information provided, the consequences of the defect are:\n",
      "\n",
      "* Improperly manufactured pump diaphragm rods may cause the pump to produce excess pressure.\n",
      "\n",
      "This could potentially lead to serious issues with the fuel system, including:\n",
      "\n",
      "* Increased risk of fuel leaks or spills\n",
      "* Potential for fuel pump failure\n",
      "* Possible engine damage or malfunction\n",
      "* Increased risk of fire or explosion\n",
      "\n",
      "It is essential to address this defect to ensure the safe and reliable operation of the vehicle.\n",
      "******************\n",
      "Example  2101\n",
      "Generated response with fine-tuned model: 1.955947 seconds\n",
      "if the platform side plates crack, the lift platform can fail, increasing the risk of injury for the lift's occupant.\n",
      "Generated response with base model: 0.654875 seconds\n",
      "\n",
      "\n",
      "According to the information provided, the consequences of the defect are:\n",
      "\n",
      "* The platform side plate of the affected wheelchair lifts may crack.\n",
      "\n",
      "This defect could potentially lead to a loss of structural integrity and compromise the safety of the wheelchair lift, which could result in serious injuries or accidents.\n",
      "******************\n",
      "Example  5178\n",
      "Generated response with fine-tuned model: 2.076930 seconds\n",
      "in the event of a fire, if the fire extinguisher does not work as expected, it can increase the risk of injury.\n",
      "Generated response with base model: 1.197545 seconds\n",
      "\n",
      "\n",
      "According to the information provided, the consequences of the defect are:\n",
      "\n",
      "1. The fire extinguisher may not discharge as expected, which could lead to a delay in putting out a fire.\n",
      "2. The fire extinguisher may require excessive force to activate, which could lead to injury or difficulty in using the extinguisher.\n",
      "3. In certain models, the nozzle may detach from the valve assembly with enough force to cause injury and render the product inoperable.\n",
      "\n",
      "These consequences could have serious implications for the safety of the occupants and users of the affected motorhomes.\n",
      "******************\n",
      "Example  1595\n",
      "Generated response with fine-tuned model: 1.495548 seconds\n",
      "a brake fluid leak can cause a loss of braking ability, increasing the risk of a crash.\n",
      "Generated response with base model: 0.954047 seconds\n",
      "\n",
      "\n",
      "Based on the information provided, the consequences of the defect are:\n",
      "\n",
      "* The master cylinder brake lines may crack and leak brake fluid.\n",
      "\n",
      "This could potentially lead to:\n",
      "\n",
      "* Reduced braking performance\n",
      "* Increased risk of accidents or loss of vehicle control\n",
      "* Brake failure, which could result in a crash or injury\n",
      "\n",
      "It is important to note that the recall is intended to address this potential safety issue and prevent any adverse consequences from occurring.\n",
      "******************\n",
      "Example  2313\n",
      "Generated response with fine-tuned model: 1.850279 seconds\n",
      "an inflator explosion may result in sharp metal fragments striking the driver or other occupants resulting in serious injury or death.\n",
      "Generated response with base model: 0.929172 seconds\n",
      "\n",
      "\n",
      "According to the information provided, the consequences of the defect are:\n",
      "\n",
      "* The replacement air bag inflators may explode due to propellant degradation occurring after long-term exposure to high absolute humidity, temperature, and temperature cycling.\n",
      "\n",
      "This means that if the defective inflators are installed in a vehicle, there is a risk of an air bag inflator explosion, which could potentially cause serious injury or even death in the event of a crash.\n",
      "******************\n",
      "Example  557\n",
      "Generated response with fine-tuned model: 1.134493 seconds\n",
      "malfunctioning exterior marker lights can increase the risk of a crash.\n",
      "Generated response with base model: 1.303891 seconds\n",
      "\n",
      "\n",
      "According to the information provided, the consequences of the defect are:\n",
      "\n",
      "* The rear marker lights, brake lights, or turn signals may not function properly.\n",
      "\n",
      "This could potentially lead to safety issues, such as:\n",
      "\n",
      "* Reduced visibility to other drivers, increasing the risk of accidents or collisions\n",
      "* Failure to alert other drivers of the vehicle's presence or intentions, increasing the risk of accidents or collisions\n",
      "* Reduced ability to stop or slow down in a timely manner, increasing the risk of accidents or collisions\n",
      "\n",
      "It is essential to address this defect to ensure the safety of the vehicle occupants and other road users.\n",
      "******************\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "evaluation_set = []\n",
    "\n",
    "for index, row in valid.iterrows():\n",
    "    print(\"Example \", index)\n",
    "\n",
    "    ## Generate response with the fine-tuned model\n",
    "    body = build_defect_request_body(row)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    response = predictor.predict(body)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Generated response with fine-tuned model: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "    response_fine_tuned = response[0]['generated_text'].strip()\n",
    "\n",
    "    print(response_fine_tuned)\n",
    "\n",
    "    ## Generate response with the base model\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        These are the information related to the defect:\n",
    "        Manufacturer: {row['MFGNAME']}\n",
    "        Component: {row['COMPNAME']}\n",
    "        Description of a defect:\n",
    "        {row['DESC_DEFECT']}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": prompt},\n",
    "                        {\"text\": \"What are the consequences?\"}]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=bedrock_model_id,\n",
    "        messages=messages,\n",
    "        inferenceConfig={\n",
    "            \"temperature\": 0.2,\n",
    "            \"topP\": 0.9,\n",
    "            \"maxTokens\": 512\n",
    "        }\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Generated response with base model: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "    response_base = response['output']['message'][\"content\"][0][\"text\"]\n",
    "    print(response_base)\n",
    "\n",
    "    evaluation_set.append({\n",
    "        \"index\": index,\n",
    "        \"target_answer\": row[\"CONEQUENCE_DEFECT\"],\n",
    "        \"fine_tuned_answer\": response_fine_tuned,\n",
    "        \"base_answer\": response_base\n",
    "    })\n",
    "\n",
    "    print(\"******************\")\n",
    "\n",
    "with open(\"llama_32_1b_evaluation_dataset.json\", \"w\") as f:\n",
    "    json.dump(evaluation_set, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU Score evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "def clean_array(string):\n",
    "    filtered_words = []\n",
    "    \n",
    "    for element in string:\n",
    "        cleaned_word = re.sub(r'[^a-zA-Z]', '', element)\n",
    "        if cleaned_word:\n",
    "            filtered_words.append(cleaned_word)\n",
    "    \n",
    "    return filtered_words\n",
    "\n",
    "def calculate_score(index, reference, hp_1, hp_2):\n",
    "    reference_split = clean_array(reference.split(\" \"))\n",
    "    \n",
    "    hp_1_split = clean_array(hp_1.split(\" \"))\n",
    "    hp_2_split = clean_array(hp_2.split(\" \"))\n",
    "    \n",
    "    BLEUscore_hp_1 = nltk.translate.bleu_score.sentence_bleu([reference_split], hp_1_split)\n",
    "    BLEUscore_hp_2 = nltk.translate.bleu_score.sentence_bleu([reference_split], hp_2_split)\n",
    "    print(\"Example \", index)\n",
    "    print(\"Fine-tuned score: \", BLEUscore_hp_1)\n",
    "    print(\"Base score: \", BLEUscore_hp_2)\n",
    "\n",
    "    print(\"******************\")\n",
    "\n",
    "    return BLEUscore_hp_1, BLEUscore_hp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example  2733\n",
      "Fine-tuned score:  0.19870007155050107\n",
      "Base score:  4.596864051685539e-155\n",
      "******************\n",
      "Example  3382\n",
      "Fine-tuned score:  1.8159331923129766e-78\n",
      "Base score:  0.06485387090109423\n",
      "******************\n",
      "Example  1198\n",
      "Fine-tuned score:  0.19895913918781657\n",
      "Base score:  1.1441414120472538e-231\n",
      "******************\n",
      "Example  2942\n",
      "Fine-tuned score:  0.7498810286408993\n",
      "Base score:  2.827440655952787e-155\n",
      "******************\n",
      "Example  5151\n",
      "Fine-tuned score:  5.502673892122423e-155\n",
      "Base score:  0\n",
      "******************\n",
      "Example  2101\n",
      "Fine-tuned score:  0.5189054572200645\n",
      "Base score:  4.028401540644523e-155\n",
      "******************\n",
      "Example  5178\n",
      "Fine-tuned score:  0.7245511487202049\n",
      "Base score:  0.05520929029092705\n",
      "******************\n",
      "Example  1595\n",
      "Fine-tuned score:  0.32128996628565337\n",
      "Base score:  1.4486065219141897e-78\n",
      "******************\n",
      "Example  2313\n",
      "Fine-tuned score:  0.948543837069451\n",
      "Base score:  1.1939947320346412e-78\n",
      "******************\n",
      "Example  557\n",
      "Fine-tuned score:  0.8931539818068694\n",
      "Base score:  9.247177469537334e-79\n",
      "******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('llama_32_1b_evaluation_dataset.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "file.close()\n",
    "\n",
    "data = []\n",
    "\n",
    "for el in evaluation_set:\n",
    "    BLEUscore_fine_tuned, BLEUscore_base = calculate_score(\n",
    "        el[\"index\"],\n",
    "        el[\"target_answer\"],\n",
    "        el[\"fine_tuned_answer\"],\n",
    "        el[\"base_answer\"])\n",
    "    \n",
    "    data.append([el[\"index\"], BLEUscore_fine_tuned, BLEUscore_base])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"index\", \"Fine-tuned score\", \"Base score\"])\n",
    "\n",
    "df[\"Fine-tuned score\"] = df[\"Fine-tuned score\"].astype(float)\n",
    "df[\"Base score\"] = df[\"Base score\"].astype(float)\n",
    "\n",
    "df.to_csv(\"./llama_32_1b_bleu_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"llama_32_1b_bleu_scores.csv\")\n",
    "\n",
    "data1 = df['Fine-tuned score']\n",
    "data2 = df['Base score']\n",
    "\n",
    "combined_data = pd.DataFrame({\n",
    "    'Fine-tuned model scores': data1,\n",
    "    'Base model scores': data2\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=combined_data)\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Distribution of Scores: Fine-tuned vs Base Model')\n",
    "\n",
    "plt.savefig('./images/llama_32_1b_bleu_scores.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLEU Score Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 1\n",
    "\n",
    "Training Arguments:\n",
    "* `epochs`: 1\n",
    "* `per_device_train_batch_size`: 2\n",
    "* `per_device_test_batch_size`: 2\n",
    "* `gradient_accumulation_steps`: 2\n",
    "* `gradient_checkpointing`: True\n",
    "\n",
    "These results are obtained by fine-tuning on 6000 rows in total, where 3000 rows of the dataset were duplicated for having both therminology on the `CONEQUENCE_DEFECT` and `CORRECTIVE_ACTION`.\n",
    "\n",
    "Total time for fine-tuning:\n",
    "* `ml.g5.12xlarge`: ~42 minutes on 4 GPUs\n",
    "\n",
    "Evaluation is performed on 10 rows extracted from the original dataset and not contained in the dataset used for the fine-tuning.\n",
    "\n",
    "BLEU score is performed with the fine-tuned model hosted on Amazon SageMaker, with an `ml.g5.4xlarge`, and the base model in Amazon Bedrock.\n",
    "\n",
    "Base model: `LLama-3.1 8B Instruct`\n",
    "\n",
    "![BLEU Scores Table](./images/llama_32_1b_bleu_scores_table.png)\n",
    "\n",
    "##### BLEU Scores graph\n",
    "\n",
    "![BLEU Scores Table](./images/llama_32_1b_bleu_scores.png)\n",
    "\n",
    "By comparing the scores in the \"Fine-tuned Score\" and \"Base Score\" columns, we can assess the performance improvement (or degradation) achieved by fine-tuning the model on the specific task or domain.\n",
    "\n",
    "The analysis suggest that in most cases, the fine-tuned model seems to be outperforming the base model. The fine-tuned model appears to be more consistent in its performance.\n",
    "\n",
    "Possible improvements:\n",
    "* Examples repetition: Provide similar examples for improving further improving the vocabulary of the fine-tuned model\n",
    "* Increse the number of epochs\n",
    "\n",
    "***\n",
    "\n",
    "Base model: `LLama-3 70B Instruct`\n",
    "\n",
    "![BLEU Scores Table](./images/llama_32_1b_bleu_scores_table_70.png)\n",
    "\n",
    "##### BLEU Scores graph\n",
    "\n",
    "![BLEU Scores Table](./images/llama_32_1b_bleu_scores_70.png)\n",
    "\n",
    "By comparing the scores in the \"Fine-tuned Score\" and \"Base Score\" columns, we can assess the performance improvement (or degradation) achieved by fine-tuning the model on the specific task or domain.\n",
    "\n",
    "The analysis suggest that in most cases, the fine-tuned model seems to be outperforming the base model. The fine-tuned model appears to be more consistent in its performance.\n",
    "\n",
    "Possible improvements:\n",
    "* Examples repetition: Provide similar examples for improving further improving the vocabulary of the fine-tuned model\n",
    "* Increse the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def levenshtein_similarity(str1, str2):\n",
    "    distance = Levenshtein.distance(str1, str2)\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    normalized_distance = 1 - (distance / max_len) if max_len > 0 else 1\n",
    "    return normalized_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example  2733\n",
      "Fine-tune score:  0.375886524822695\n",
      "Base score:  0.26454033771106944\n",
      "******************\n",
      "Example  3382\n",
      "Fine-tune score:  0.4086021505376344\n",
      "Base score:  0.24761904761904763\n",
      "******************\n",
      "Example  1198\n",
      "Fine-tune score:  0.4506172839506173\n",
      "Base score:  0.261744966442953\n",
      "******************\n",
      "Example  2942\n",
      "Fine-tune score:  0.8654970760233918\n",
      "Base score:  0.18100890207715137\n",
      "******************\n",
      "Example  5151\n",
      "Fine-tune score:  0.2628205128205128\n",
      "Base score:  0.028328611898016942\n",
      "******************\n",
      "Example  2101\n",
      "Fine-tune score:  0.7076271186440678\n",
      "Base score:  0.29032258064516125\n",
      "******************\n",
      "Example  5178\n",
      "Fine-tune score:  0.8571428571428572\n",
      "Base score:  0.16728624535315983\n",
      "******************\n",
      "Example  1595\n",
      "Fine-tune score:  0.49090909090909096\n",
      "Base score:  0.214123006833713\n",
      "******************\n",
      "Example  2313\n",
      "Fine-tune score:  0.9851851851851852\n",
      "Base score:  0.21908893709327548\n",
      "******************\n",
      "Example  557\n",
      "Fine-tune score:  0.9444444444444444\n",
      "Base score:  0.12062256809338523\n",
      "******************\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('llama_32_1b_evaluation_dataset.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "file.close()\n",
    "\n",
    "data = [] \n",
    "\n",
    "for el in evaluation_set:\n",
    "    print(\"Example \", el[\"index\"])\n",
    "    score_fine_tuned = levenshtein_similarity(el[\"fine_tuned_answer\"], el[\"target_answer\"])\n",
    "    print(\"Fine-tune score: \", score_fine_tuned)\n",
    "    score_base = levenshtein_similarity(el[\"base_answer\"], el[\"target_answer\"])\n",
    "    print(\"Base score: \", score_base)\n",
    "    print(\"******************\")\n",
    "\n",
    "    data.append([el[\"index\"], score_fine_tuned, score_base])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"index\", \"Fine-tuned score\", \"Base score\"])\n",
    "\n",
    "df[\"Fine-tuned score\"] = df[\"Fine-tuned score\"].astype(float)\n",
    "df[\"Base score\"] = df[\"Base score\"].astype(float)\n",
    "\n",
    "df.to_csv(\"./llama_32_1b_levenshtein_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"llama_32_1b_levenshtein_scores.csv\")\n",
    "\n",
    "data1 = df['Fine-tuned score']\n",
    "data2 = df['Base score']\n",
    "\n",
    "combined_data = pd.DataFrame({\n",
    "    'Fine-tuned model scores': data1,\n",
    "    'Base model scores': data2\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=combined_data)\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Distribution of Scores: Fine-tuned vs Base Model')\n",
    "\n",
    "plt.savefig('./images/llama_32_1b_levenshtein_scores.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized Levenshtein Score Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1\n",
    "\n",
    "Training Arguments:\n",
    "* `epochs`: 1\n",
    "* `per_device_train_batch_size`: 2\n",
    "* `per_device_test_batch_size`: 1\n",
    "* `gradient_accumulation_steps`: 2\n",
    "* `gradient_checkpointing`: True\n",
    "\n",
    "These results are obtained by fine-tuning on 6000 rows in total, where 3000 rows of the dataset were duplicated for having both therminology on the `CONEQUENCE_DEFECT` and `CORRECTIVE_ACTION`.\n",
    "\n",
    "Total time for fine-tuning:\n",
    "* `ml.g5.12xlarge`: ~39 minutes on 4 GPUs\n",
    "\n",
    "Evaluation is performed on 10 rows extracted from the original dataset and not contained in the dataset used for the fine-tuning.\n",
    "\n",
    "Levenshtein score is performed with the fine-tuned model hosted on Amazon SageMaker, with an `ml.g5.4xlarge`, and the base model in Amazon Bedrock.\n",
    "\n",
    "Base model: `LLama-3.1 8B Instruct`\n",
    "\n",
    "![BLEU Scores Table](./images/llama_32_1b_levenshtein_scores_table.png)\n",
    "\n",
    "##### BLEU Scores graph\n",
    "\n",
    "![BLEU Scores Table](./images/llama_32_1b_levenshtein_scores.png)\n",
    "\n",
    "By comparing the scores in the \"Fine-tuned Score\" and \"Base Score\" columns, we can assess the performance improvement (or degradation) achieved by fine-tuning the model on the specific task or domain.\n",
    "\n",
    "The analysis suggest that the fine-tuned model is clearly outperforming the base model across almost all examples. This suggests that the fine-tuning process has been quite effective in improving the model's accuracy for this specific task.\n",
    "\n",
    "In the Normalized Levenshtein distance, the range is from 0 to 1, where closer to 0 means better performance. The fine-tuned model often achieves scores closer to 0, indicating higher accuracy.\n",
    "\n",
    "Possible improvements:\n",
    "* Examples repetition: Provide similar examples for improving further improving the vocabulary of the fine-tuned model\n",
    "* Increse the number of epochs\n",
    "\n",
    "***\n",
    "\n",
    "Base model: `LLama-3 70B Instruct`\n",
    "\n",
    "![BLEU Scores Table](./images/llama_32_1b_levenshtein_scores_table_70.png)\n",
    "\n",
    "##### BLEU Scores graph\n",
    "\n",
    "![BLEU Scores Table](./images/llama_32_1b_levenshtein_scores_70.png)\n",
    "\n",
    "By comparing the scores in the \"Fine-tuned Score\" and \"Base Score\" columns, we can assess the performance improvement (or degradation) achieved by fine-tuning the model on the specific task or domain.\n",
    "\n",
    "The analysis suggest that the fine-tuned model is clearly outperforming the base model across almost all examples. This suggests that the fine-tuning process has been quite effective in improving the model's accuracy for this specific task.\n",
    "\n",
    "In the Normalized Levenshtein distance, the range is from 0 to 1, where closer to 0 means better performance. The fine-tuned model often achieves scores closer to 0, indicating higher accuracy.\n",
    "\n",
    "Possible improvements:\n",
    "* Examples repetition: Provide similar examples for improving further improving the vocabulary of the fine-tuned model\n",
    "* Increse the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
